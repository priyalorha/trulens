{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ““ TruLens with Outside Logs\n",
    "\n",
    "If your application was run (and logged) outside of TruLens, TruVirtual can be used to ingest and evaluate the logs.\n",
    "\n",
    "The first step to loading your app logs into TruLens is creating a virtual app. This virtual app can be a plain dictionary or use our VirtualApp class to store any information you would like. You can refer to these values for evaluating feedback.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/quickstart/existing_data_quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_app = dict(\n",
    "    llm=dict(\n",
    "        modelname=\"some llm component model name\"\n",
    "    ),\n",
    "    template=\"information about the template I used in my app\",\n",
    "    debug=\"all of these fields are completely optional\"\n",
    ")\n",
    "from trulens_eval import Select\n",
    "from trulens_eval.tru_virtual import VirtualApp\n",
    "\n",
    "virtual_app = VirtualApp(virtual_app) # can start with the prior dictionary\n",
    "virtual_app[Select.RecordCalls.llm.maxtokens] = 1024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When setting up the virtual app, you should also include any components that you would like to evaluate in the virtual app. This can be done using the Select class. Using selectors here lets use reuse the setup you use to define feedback functions. Below you can see how to set up a virtual app with a retriever component, which will be used later in the example for feedback evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Select\n",
    "retriever = Select.RecordCalls.retriever\n",
    "synthesizer = Select.RecordCalls.synthesizer\n",
    "\n",
    "virtual_app[retriever] = \"retriever\"\n",
    "virtual_app[synthesizer] = \"synthesizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.tru_virtual import VirtualRecord\n",
    "\n",
    "# The selector for a presumed context retrieval component's call to\n",
    "# `get_context`. The names are arbitrary but may be useful for readability on\n",
    "# your end.\n",
    "context_call = retriever.get_context\n",
    "generation = synthesizer.generate\n",
    "\n",
    "rec1 = VirtualRecord(\n",
    "    main_input=\"Where is Germany?\",\n",
    "    main_output=\"Germany is in Europe\",\n",
    "    calls=\n",
    "        {\n",
    "            context_call: dict(\n",
    "                args=[\"Where is Germany?\"],\n",
    "                rets=[\"Germany is a country located in Europe.\"]\n",
    "            ),\n",
    "            generation: dict(\n",
    "                args=[\"\"\"\n",
    "                    We have provided the below context: \\n\n",
    "                    ---------------------\\n\n",
    "                    Germany is a country located in Europe.\n",
    "                    ---------------------\\n\n",
    "                    Given this information, please answer the question: \n",
    "                    Where is Germany?\n",
    "                      \"\"\"],\n",
    "                rets=[\"Germany is a country located in Europe.\"]\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "rec2 = VirtualRecord(\n",
    "    main_input=\"Where is Germany?\",\n",
    "    main_output=\"Poland is in Europe\",\n",
    "    calls=\n",
    "        {\n",
    "            context_call: dict(\n",
    "                args=[\"Where is Germany?\"],\n",
    "                rets=[\"Poland is a country located in Europe.\"]\n",
    "            ),\n",
    "            generation: dict(\n",
    "                args=[\"\"\"\n",
    "                    We have provided the below context: \\n\n",
    "                    ---------------------\\n\n",
    "                    Germany is a country located in Europe.\n",
    "                    ---------------------\\n\n",
    "                    Given this information, please answer the question: \n",
    "                    Where is Germany?\n",
    "                      \"\"\"],\n",
    "                rets=[\"Poland is a country located in Europe.\"]\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "data = [rec1, rec2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've ingested constructed the virtual records, we can build our feedback functions. This is done just the same as normal, except the context selector will instead refer to the new context_call we added to the virtual record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI\n",
    "from trulens_eval.feedback.feedback import Feedback\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "# Select context to be used in feedback. We select the return values of the\n",
    "# virtual `get_context` call in the virtual `retriever` component. Names are\n",
    "# arbitrary except for `rets`.\n",
    "context = context_call.rets[:]\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(openai.qs_relevance)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    ")\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider=openai)\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(context.collect())\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = (\n",
    "    Feedback(openai.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
    "    .on_input_output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.tru_virtual import TruVirtual\n",
    "\n",
    "virtual_recorder = TruVirtual(\n",
    "    app_id=\"a virtual app\",\n",
    "    app=virtual_app,\n",
    "    feedbacks=[f_context_relevance, f_groundedness, f_qa_relevance],\n",
    "    feedback_mode = \"deferred\" # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in data:\n",
    "    virtual_recorder.add_record(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "\n",
    "tru.run_dashboard(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.start_evaluator()\n",
    "\n",
    "# tru.stop_evaluator() # stop if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trucanopy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
